{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.0.18.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n\nimport os\ndata_dir = '../input/pretrained/'\ncache_dir ='/root/.cache/torch/hub/checkpoints/'\n\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n\nfrom shutil import copyfile\nfor fname in os.listdir(data_dir):    \n    src = data_dir + fname\n    dest = cache_dir + fname\n    copyfile(src, dest)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/effnetpytrochwhl/efficientnet_pytorch-0.7.0-py3-none-any.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random, re, string, gc\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport sklearn\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import PCA\n\n\nfrom tqdm.notebook import tqdm\n\n\nimport  cuml, cupy, cudf\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\n\nfrom PIL import Image\n\nimport torch\ntorch.manual_seed(1010)\n\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom efficientnet_pytorch import EfficientNet\n\n\nimport nltk\nfrom nltk.corpus import stopwords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Utils**","metadata":{}},{"cell_type":"code","source":"def combine_for_sub(row):\n    x = np.concatenate([row.img_preds, row.text_preds])\n    return \" \".join(np.unique(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(1010)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Image**\n","metadata":{}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    def __init__(self, img_path, transform):\n        self.img_path = img_path\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        img = Image.open(self.img_path[idx]).convert('RGB')\n        img = self.transform(img)\n        return img\n    \n    def __len__(self):\n        return len(self.img_path)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeNet(nn.Module):\n    def __init__(self):\n        super(ShopeeNet, self).__init__()\n        model = EfficientNet.from_pretrained('efficientnet-b3')\n        model.eval()\n        self.model = model\n        \n    def forward(self, img):\n        out = self.model.extract_features(img)\n        out = self.model._avg_pooling(out)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_predictions(df, embeddings, threshold = 0.54):\n    \n    if len(df) > 3:\n        KNN = 50\n    else : \n        KNN = 3\n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    predictions = []\n    for dist, idx in tqdm(zip(distances, indices)):\n        posting_ids = df.iloc[cupy.asnumpy(idx[dist < 0.54])].posting_id.values\n        predictions.append(posting_ids)\n        \n    del model, distances, indices, dist, idx, posting_ids\n    gc.collect()\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_embeddings(image_paths):\n    embeds = []\n    \n    model = ShopeeNet()\n    model = model.to('cuda')\n\n    image_dataset = ShopeeDataset(\n        image_paths,\n        transforms.Compose([\n            transforms.Resize((512, 512)),\n            transforms.CenterCrop((200, 200)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    )\n\n    image_loader = torch.utils.data.DataLoader(\n        image_dataset,\n        batch_size = 12,\n        shuffle = False,\n        pin_memory=True,\n        drop_last=False,\n        num_workers = 4\n    )\n    \n    \n    with torch.no_grad():\n        for img in tqdm(image_loader): \n            img = img.cuda()\n            feat = model(img)\n            feat = feat.reshape(feat.shape[0], feat.shape[1])\n            image_embeddings = feat.detach().cpu().numpy()\n            embeds.append(image_embeddings)\n    \n    \n    del model\n    image_embeddings = np.concatenate(embeds)\n    image_embeddings = normalize(image_embeddings)    \n    print(f'Image embeddings shape is {image_embeddings.shape}')\n    del embeds\n    gc.collect()\n    return image_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Text**","metadata":{}},{"cell_type":"code","source":"def clean_title(row):\n    title = row.title\n    stop = stopwords.words('english')\n    title = [x for x in title.split() if not x in stop]\n    title = \" \".join(title)\n    title = title.lower()\n    title = re.sub(r\"\\-\",\"\",title)\n    title = re.sub(r\"\\+\",\"\",title)\n    title = re.sub (r\"&\",\"and\",title)\n    title = re.sub(r\"\\|\",\"\",title)\n    title = re.sub(r\"\\\\\",\"\",title)\n    title = re.sub(r\"\\W\",\" \",title)\n    for p in string.punctuation :\n        title = re.sub(r\"f{p}\",\"\",title)\n    \n    title = re.sub(r\"\\s+\",\" \",title)\n    \n    return title","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text_predictions(df, max_features = 25_000, threshold = 0.54):\n    \n    text = cudf.Series.from_pandas(df.apply(clean_title, axis=1))    \n    model = TfidfVectorizer(stop_words=None, binary=True, max_features=max_features)\n    text_embeddings = model.fit_transform(text).toarray()\n    preds = []\n    CHUNK = 1024*4\n\n    print('Finding similar titles...')\n    CTS = len(df)//CHUNK\n    if len(df)%CHUNK!=0: CTS += 1\n    for j in range( CTS ):\n\n        a = j*CHUNK\n        b = (j+1)*CHUNK\n        b = min(b,len(df))\n        print('chunk',a,'to',b)\n\n        # COSINE SIMILARITY DISTANCE\n        distances = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n\n        for k in range(b-a):\n            idx = cupy.where(distances[k] > 0.7)[0]\n            o = df.iloc[cupy.asnumpy(idx)].posting_id.values\n            preds.append(o)\n    \n    del text, model, text_embeddings, distances, idx, o\n    gc.collect()\n    return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Predictions**","metadata":{}},{"cell_type":"code","source":"path = '../input/shopee-product-matching/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path + 'test.csv')\ndf['image'] = path + 'test_images/' + df['image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_embeddings = get_image_embeddings(df.image.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_predictions = get_image_predictions(df, image_embeddings)\ntext_predictions = get_text_predictions(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission**","metadata":{}},{"cell_type":"code","source":"df['img_preds'] = image_predictions\ndf['text_preds'] = text_predictions\ndf['matches'] = df.apply(combine_for_sub, axis = 1)\ndf[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}