{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sklearn\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "train_path = 'data/train_images/'\n",
    "test_path = 'data/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv(path + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (34250, 5)\n",
      "N_unique label_group: 11014\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data shape: {traindf.shape}\")\n",
    "print(f\"N_unique label_group: {traindf.label_group.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['image'] = train_path + traindf['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = traindf.drop_duplicates(subset=['image']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = traindf.groupby('label_group').posting_id.unique().to_dict()\n",
    "traindf['target'] = traindf.label_group.map(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = traindf.groupby('image_phash').posting_id.unique().to_dict()\n",
    "traindf['phash_dups'] = traindf.image_phash.map(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(row):\n",
    "    x = np.concatenate([row.phash_dups, row.cnn, row.knn])\n",
    "    return np.unique(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len(np.intersect1d(row.target, row[col]))\n",
    "        return 2 * n / (len(row.target) + len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline score = 0.5446525227019672\n"
     ]
    }
   ],
   "source": [
    "traindf['f1'] = traindf.apply(getMetric('phash_dups'), axis=1)\n",
    "print('Baseline score =', traindf.f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(1010)\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, img_path, transform):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_path[idx]).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee_dataset = ShopeeDataset(\n",
    "    traindf.image.values,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "shopee_loader = torch.utils.data.DataLoader(\n",
    "    shopee_dataset,\n",
    "    batch_size = 10,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShopeeNet, self).__init__()\n",
    "        \n",
    "\n",
    "        model = models.resnet50(True)\n",
    "        model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        model.eval()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopee_model = ShopeeNet()\n",
    "shopee_model = shopee_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d129ff0bb254be5a6c1d9e63e8e8fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedings = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(shopee_loader):\n",
    "        data = data.to('cuda')\n",
    "        emb = shopee_model(data)\n",
    "        emb = emb.reshape(emb.shape[0], emb.shape[1])\n",
    "        emb = emb.data.cpu().numpy()\n",
    "        \n",
    "        embedings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings = np.vstack(embedings)\n",
    "embedings = normalize(embedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=50, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = 50\n",
    "model = NearestNeighbors(n_neighbors=KNN)\n",
    "model.fit(embedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 8192\n",
      "chunk 8192 to 12288\n",
      "chunk 12288 to 16384\n",
      "chunk 16384 to 20480\n",
      "chunk 20480 to 24576\n",
      "chunk 24576 to 28672\n",
      "chunk 28672 to 32412\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "CTS = len(embedings) // CHUNK\n",
    "if len(embedings) % CHUNK != 0: CTS += 1\n",
    "    \n",
    "for j in range (CTS):\n",
    "    a = j * CHUNK\n",
    "    b = (j + 1) * CHUNK\n",
    "    b = min(b, len(embedings))\n",
    "    print('chunk', a,'to', b)\n",
    "    \n",
    "    distances, indices = model.kneighbors(embedings[a:b])\n",
    "    \n",
    "    for dist, idx in zip(distances, indices):\n",
    "        o = traindf.iloc[idx[dist > .6]].posting_id.values\n",
    "        preds.append(o)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindf['knn'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 to 4096\n",
      "chunk 4096 to 8192\n",
      "chunk 8192 to 12288\n",
      "chunk 12288 to 16384\n",
      "chunk 16384 to 20480\n",
      "chunk 20480 to 24576\n",
      "chunk 24576 to 28672\n",
      "chunk 28672 to 32412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "CTS = len(embedings) // CHUNK\n",
    "if len(embedings) % CHUNK != 0: CTS += 1\n",
    "for i in range(CTS):\n",
    "    \n",
    "    a = i * CHUNK\n",
    "    b = (i + 1) * CHUNK\n",
    "    b = min(b, len(embedings))\n",
    "    print('chunk', a,'to', b)\n",
    "    \n",
    "    distances = np.matmul(embedings, embedings[a:b].T).T\n",
    "\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = np.where(distances[k,]>0.95)[0]\n",
    "        o = traindf.iloc[IDX].posting_id.values\n",
    "        preds.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN KNN score = 0.6436852975694984\n"
     ]
    }
   ],
   "source": [
    "traindf['cnn'] = preds\n",
    "\n",
    "traindf['f1_cnn'] = traindf.apply(getMetric('cnn'), axis=1)\n",
    "print('CNN KNN score =', traindf.f1_cnn.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['matches'] = traindf.apply(combine, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashes + CNN + KNN score = 0.6435139394912119\n"
     ]
    }
   ],
   "source": [
    "traindf['f1'] = traindf.apply(getMetric('matches'), axis =1)\n",
    "print ('Hashes + CNN + KNN score =', traindf.f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_DBSCAN = DBSCAN(eps=0.07, min_samples=2, metric='cosine').fit(embedings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN DBSCAN score = 0.4150762569220733\n"
     ]
    }
   ],
   "source": [
    "traindf['clusters_dbscan'] = clustering_DBSCAN.labels_\n",
    "clustered = (traindf['clusters_dbscan'] != -1)\n",
    "tmp = traindf.loc[clustered].groupby('clusters_dbscan').posting_id.unique().to_dict()\n",
    "tmp[-1] = []\n",
    "for key, value in tmp.items():\n",
    "    if len(value) > 50:\n",
    "        tmp[key] = value[:50]\n",
    "\n",
    "        \n",
    "traindf['cnn_dbscan'] = traindf['clusters_dbscan'].map(tmp)\n",
    "traindf['f1_dbscan'] = traindf.apply(getMetric('cnn_dbscan'), axis=1)\n",
    "print('CNN DBSCAN score =', traindf.f1_dbscan.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_OPTICS = OPTICS(min_samples=2, max_eps=0.05, metric='cosine').fit(embedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN OPTICS score = 0.33722592912940347\n"
     ]
    }
   ],
   "source": [
    "traindf['clusters_optics'] = clustering_OPTICS.labels_\n",
    "clustered = (traindf['clusters_optics'] != -1)\n",
    "tmp = traindf.loc[clustered].groupby('clusters_optics').posting_id.unique().to_dict()\n",
    "tmp[-1] = []\n",
    "for key, value in tmp.items():\n",
    "    if len(value) > 50:\n",
    "        tmp[key] = value[:50]\n",
    "\n",
    "        \n",
    "traindf['cnn_optics'] = traindf['clusters_optics'].map(tmp)\n",
    "traindf['f1_optics'] = traindf.apply(getMetric('cnn_optics'), axis=1)\n",
    "print('CNN OPTICS score =', traindf.f1_optics.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
